[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Analytics Lab",
    "section": "",
    "text": "Hello!! My name is Cevat Enes.\nThis is my personal webpage.\nPlease stay tuned to follow my works on data analytics, blog posts, and more.\n\n\n\n Back to top"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project: Exploring CPI and R&D Impact on Industrial Production in Turkey",
    "section": "",
    "text": "Welcome to my project page.\nKeep an eye on this space to stay updated with my project activities."
  },
  {
    "objectID": "project.html#data-source",
    "href": "project.html#data-source",
    "title": "Project: Exploring CPI and R&D Impact on Industrial Production in Turkey",
    "section": "2.1 Data Source",
    "text": "2.1 Data Source\nThe data source is Türkiye İstatistik Kurumu (Turkish Statistical Institute - TÜİK) database.\nTo access the folder containing the .RData files used in this analysis, please reach out to the dataset from following link.\nReach out to the .RData files"
  },
  {
    "objectID": "project.html#general-information-about-data",
    "href": "project.html#general-information-about-data",
    "title": "Project: Exploring CPI and R&D Impact on Industrial Production in Turkey",
    "section": "2.2 General Information About Data",
    "text": "2.2 General Information About Data\nSales Quantity: Total sales volume of products domestically and internationally within the reference year or preceding years. Enterprise Count: Number of enterprises providing information in the annual industrial product survey, including estimates for non-responding enterprises.\nProduction Quantity: Total quantity of products manufactured within the reference year, irrespective of sales, stocking, or internal use.\nProduction Value: Total value of products manufactured within the reference year, excluding sales, stocking, or internal use.\nSales Value: Total sales value of products domestically and internationally within the reference year, including packaging costs but excluding VAT, excise duties, recycling packaging values, separately charged customer transport and delivery costs, customer discounts, payments for returned goods, and government subsidies.\nCPI: Annual rate of change of consumer price index numbers\nDistribution of R&D expenditures in financial and non-financial corporations by types of R&D: the percentage distribution of various types of R&D activities through the years.\nGross domestic expenditure on R&D by sector and source of funds: the expenditure amount of sectors from the various funds through the years.\nThe datasets, explanatory data analyses and remarkable findings about the Product, R&D and CPI dataset bundles are presented by TUIK. Also, the original data can be found. It can be reached out from following links:\nAnnual Industrial Product (PRODCOM) Statistics - 2022\nResearch and Development Activities Survey -2022\nConsumer Price Index - December 2023"
  },
  {
    "objectID": "project.html#reason-of-choice",
    "href": "project.html#reason-of-choice",
    "title": "Project: Exploring CPI and R&D Impact on Industrial Production in Turkey",
    "section": "2.3 Reason of Choice",
    "text": "2.3 Reason of Choice\nThese datasets were chosen to conduct a comprehensive analysis of the interplay between R&D investments, economic performance, and industrial production in Turkey’s manufacturing sector. By integrating data from various sources, this project aims to provide valuable insights into the drivers of industrial growth and innovation. It seeks to identify potential cause-and-effect relationships, questioning the significance of R&D for product development and its impact on production. Additionally, the study will explore how organizations adapt their R&D strategies in response to economic conditions."
  },
  {
    "objectID": "project.html#preprocessing",
    "href": "project.html#preprocessing",
    "title": "Project: Exploring CPI and R&D Impact on Industrial Production in Turkey",
    "section": "2.4 Preprocessing",
    "text": "2.4 Preprocessing\nThe dataset retrieved from the database was initially stored in “.xlsx” format as tables, which required conversion into importable formats suitable for analysis. Subsequently, the dataset exhibited structured product codes with associated descriptions and unit measurements, organized hierarchically. Key preprocessing tasks involved:\nParsing and structuring the hierarchical product codes for meaningful analysis. Mapping product codes to their respective descriptions to facilitate interpretation. Ensuring uniformity in units across all product codes (e.g., standardizing to kilograms). Addressing duplicates, redundancies, and missing values within the dataset to ensure data integrity. Performing aggregation and summarization for broader product categories based on hierarchical relationships.\nThese preprocessing steps were essential to transform the dataset into a clean and structured format suitable for detailed analysis."
  },
  {
    "objectID": "project.html#exploratory-data-analysis",
    "href": "project.html#exploratory-data-analysis",
    "title": "Project: Exploring CPI and R&D Impact on Industrial Production in Turkey",
    "section": "3.1 Exploratory Data Analysis",
    "text": "3.1 Exploratory Data Analysis\nPotential analyses during EDA include:\nVisualizing trends in R&D expenditures over time and by sector Examining correlations between R&D investments, industrial production metrics, and consumer price levels Identifying key factors influencing variations in industrial product trends Clustering analysis to segment industries based on R&D spending and economic performance"
  },
  {
    "objectID": "project.html#trend-analysis",
    "href": "project.html#trend-analysis",
    "title": "Project: Exploring CPI and R&D Impact on Industrial Production in Turkey",
    "section": "3.2 Trend Analysis",
    "text": "3.2 Trend Analysis\nxxxxxx"
  },
  {
    "objectID": "project.html#model-fitting",
    "href": "project.html#model-fitting",
    "title": "Project: Exploring CPI and R&D Impact on Industrial Production in Turkey",
    "section": "3.3 Model Fitting",
    "text": "3.3 Model Fitting\nxxxxxx"
  },
  {
    "objectID": "project.html#results",
    "href": "project.html#results",
    "title": "Project: Exploring CPI and R&D Impact on Industrial Production in Turkey",
    "section": "3.4 Results",
    "text": "3.4 Results\nxxxxxx"
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "My Assignments",
    "section": "",
    "text": "On this page, I showcase the assignment I conducted for the [Spring 2024] EMU660 Decision Making with Analytics course.\nPlease use left menu to navigate through my assignments.\n\n\n\n Back to top",
    "crumbs": [
      "My Assignments"
    ]
  },
  {
    "objectID": "about.html#employements",
    "href": "about.html#employements",
    "title": "About Me",
    "section": "Employements",
    "text": "Employements\n\nFirm Optiyol, position Optimization Scientist, year 2021- ongoing.\nFirm Roketsan, position Supply Chain Planning Engineer, year 2018-2021"
  },
  {
    "objectID": "about.html#internships",
    "href": "about.html#internships",
    "title": "About Me",
    "section": "Internships",
    "text": "Internships\n\nFirm Aselsan, position Intern at Production Planning Department, year 2017\nFirm: Tusaş, position Co-op Intern at Capacity Planning Department, year 2016"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "My Blog",
    "section": "",
    "text": "This page is under construction.\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/assignments/assignment-1.html",
    "href": "docs/assignments/assignment-1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "1 + 1\n\n[1] 2\n\n\nMy first assignment has two parts."
  },
  {
    "objectID": "assignments/assignment-1.html",
    "href": "assignments/assignment-1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "My first assignment has three parts.\n\n\nVeri Bilimi ve Endüstri Mühendisliği Üzerine Sohbetler - Cem Vardar & Erdi Dasdemir\nMr. Cem Vardar is an experienced Data Scientist with a focus on prescriptive analytics, optimization. He talks about problem solving, industrial engineering and current trends on data analytics. He also mentions about the data related roles and the problem types that should be handled in that role. He presents a study showing the desired qualities and charecteristics for data science roles. Lastly, as a experienced scientist, he shares some valuable suggestions and reading list and finishes with an interactive Q&A session.\n\n\n\n\n\n\ndata(mtcars)\n# Define custom summary function\ncustom_summary &lt;- function(data) {\n  summary_list &lt;- list(\n    mean = mean(data),\n    median = median(data),\n    sd = sd(data),\n    min = min(data),\n    max = max(data)\n  )\n  return(summary_list)\n}\n\nsummary_mpg &lt;- custom_summary(mtcars$mpg)\nprint(summary_mpg)\n\n$mean\n[1] 20.09062\n\n$median\n[1] 19.2\n\n$sd\n[1] 6.026948\n\n$min\n[1] 10.4\n\n$max\n[1] 33.9\n\n\n\n# Iterate over numeric columns of mtcars dataset and apply custom summary function\nfor (col in names(mtcars)) {\n  if (is.numeric(mtcars[[col]])) {\n    cat(\"Summary for column:\", col, \"\\n\")\n    print(custom_summary(mtcars[[col]]))\n    cat(\"\\n\")\n  }\n}\n\nSummary for column: mpg \n$mean\n[1] 20.09062\n\n$median\n[1] 19.2\n\n$sd\n[1] 6.026948\n\n$min\n[1] 10.4\n\n$max\n[1] 33.9\n\n\nSummary for column: cyl \n$mean\n[1] 6.1875\n\n$median\n[1] 6\n\n$sd\n[1] 1.785922\n\n$min\n[1] 4\n\n$max\n[1] 8\n\n\nSummary for column: disp \n$mean\n[1] 230.7219\n\n$median\n[1] 196.3\n\n$sd\n[1] 123.9387\n\n$min\n[1] 71.1\n\n$max\n[1] 472\n\n\nSummary for column: hp \n$mean\n[1] 146.6875\n\n$median\n[1] 123\n\n$sd\n[1] 68.56287\n\n$min\n[1] 52\n\n$max\n[1] 335\n\n\nSummary for column: drat \n$mean\n[1] 3.596563\n\n$median\n[1] 3.695\n\n$sd\n[1] 0.5346787\n\n$min\n[1] 2.76\n\n$max\n[1] 4.93\n\n\nSummary for column: wt \n$mean\n[1] 3.21725\n\n$median\n[1] 3.325\n\n$sd\n[1] 0.9784574\n\n$min\n[1] 1.513\n\n$max\n[1] 5.424\n\n\nSummary for column: qsec \n$mean\n[1] 17.84875\n\n$median\n[1] 17.71\n\n$sd\n[1] 1.786943\n\n$min\n[1] 14.5\n\n$max\n[1] 22.9\n\n\nSummary for column: vs \n$mean\n[1] 0.4375\n\n$median\n[1] 0\n\n$sd\n[1] 0.5040161\n\n$min\n[1] 0\n\n$max\n[1] 1\n\n\nSummary for column: am \n$mean\n[1] 0.40625\n\n$median\n[1] 0\n\n$sd\n[1] 0.4989909\n\n$min\n[1] 0\n\n$max\n[1] 1\n\n\nSummary for column: gear \n$mean\n[1] 3.6875\n\n$median\n[1] 4\n\n$sd\n[1] 0.7378041\n\n$min\n[1] 3\n\n$max\n[1] 5\n\n\nSummary for column: carb \n$mean\n[1] 2.8125\n\n$median\n[1] 2\n\n$sd\n[1] 1.6152\n\n$min\n[1] 1\n\n$max\n[1] 8\n\n\n\n\n\n\n\n\n\nlibrary(dslabs)\ndata(\"na_example\")\nprint(\"Dataset with NA values:\")\n\n[1] \"Dataset with NA values:\"\n\nprint(na_example)\n\n   [1]  2  1  3  2  1  3  1  4  3  2  2 NA  2  2  1  4 NA  1  1  2  1  2  2  1\n  [25]  2  5 NA  2  2  3  1  2  4  1  1  1  4  5  2  3  4  1  2  4  1  1  2  1\n  [49]  5 NA NA NA  1  1  5  1  3  1 NA  4  4  7  3  2 NA NA  1 NA  4  1  2  2\n  [73]  3  2  1  2  2  4  3  4  2  3  1  3  2  1  1  1  3  1 NA  3  1  2  2  1\n  [97]  2  2  1  1  4  1  1  2  3  3  2  2  3  3  3  4  1  1  1  2 NA  4  3  4\n [121]  3  1  2  1 NA NA NA NA  1  5  1  2  1  3  5  3  2  2 NA NA NA NA  3  5\n [145]  3  1  1  4  2  4  3  3 NA  2  3  2  6 NA  1  1  2  2  1  3  1  1  5 NA\n [169] NA  2  4 NA  2  5  1  4  3  3 NA  4  3  1  4  1  1  3  1  1 NA NA  3  5\n [193]  2  2  2  3  1  2  2  3  2  1 NA  2 NA  1 NA NA  2  1  1 NA  3 NA  1  2\n [217]  2  1  3  2  2  1  1  2  3  1  1  1  4  3  4  2  2  1  4  1 NA  5  1  4\n [241] NA  3 NA NA  1  1  5  2  3  3  2  4 NA  3  2  5 NA  2  3  4  6  2  2  2\n [265] NA  2 NA  2 NA  3  3  2  2  4  3  1  4  2 NA  2  4 NA  6  2  3  1 NA  2\n [289]  2 NA  1  1  3  2  3  3  1 NA  1  4  2  1  1  3  2  1  2  3  1 NA  2  3\n [313]  3  2  1  2  3  5  5  1  2  3  3  1 NA NA  1  2  4 NA  2  1  1  1  3  2\n [337]  1  1  3  4 NA  1  2  1  1  3  3 NA  1  1  3  5  3  2  3  4  1  4  3  1\n [361] NA  2  1  2  2  1  2  2  6  1  2  4  5 NA  3  4  2  1  1  4  2  1  1  1\n [385]  1  2  1  4  4  1  3 NA  3  3 NA  2 NA  1  2  1  1  4  2  1  4  4 NA  1\n [409]  2 NA  3  2  2  2  1  4  3  6  1  2  3  1  3  2  2  2  1  1  3  2  1  1\n [433]  1  3  2  2 NA  4  4  4  1  1 NA  4  3 NA  1  3  1  3  2  4  2  2  2  3\n [457]  2  1  4  3 NA  1  4  3  1  3  2 NA  3 NA  1  3  1  4  1  1  1  2  4  3\n [481]  1  2  2  2  3  2  3  1  1 NA  3  2  1  1  2 NA  2  2  2  3  3  1  1  2\n [505] NA  1  2  1  1  3  3  1  3  1  1  1  1  1  2  5  1  1  2  2  1  1 NA  1\n [529]  4  1  2  4  1  3  2 NA  1  1 NA  2  1  1  4  2  3  3  1  5  3  1  1  2\n [553] NA  1  1  3  1  3  2  4 NA  2  3  2  1  2  1  1  1  2  2  3  1  5  2 NA\n [577]  2 NA  3  2  2  2  1  5  3  2  3  1 NA  3  1  2  2  2  1  2  2  4 NA  6\n [601]  1  2 NA  1  1  2  2  3 NA  3  2  3  3  4  2 NA  2 NA  4 NA  1  1  2  2\n [625]  3  1  1  1  3 NA  2  5 NA  7  1 NA  4  3  3  1 NA  1  1  1  1  3  2  4\n [649]  2  2  3 NA NA  1  4  3  2  2  2  3  2  4  2  2  4 NA NA NA  6  3  3  1\n [673]  4  4  2  1 NA  1  6 NA  3  3  2  1  1  6 NA  1  5  1 NA  2  6  2 NA  4\n [697]  1  3  1  2 NA  1  1  3  1  2  4  2  1  3  2  4  3  2  2  1  1  5  6  4\n [721]  2  2  2  2  4 NA  1  2  2  2  2  4  5 NA NA NA  4  3  3  3  2  4  2  4\n [745] NA NA NA NA  2  1 NA  2  4  3  2 NA  2  3  1  3  4 NA  1  2  1  2 NA  3\n [769]  1  2  1  2  1  2  1  2  2  2  2  1  1  3  3  1  3  4  3 NA NA  4  2  3\n [793]  2  1  3  2  4  2  2  3  1  2  4  3  3  4 NA  1  4  2  1  1  1  3  1  5\n [817]  2  2  4  2 NA  1  3  1  2 NA  1  2  1  2  1 NA  1  3  2  3  2 NA  2  1\n [841]  4  2 NA NA NA  2  4  2 NA NA  3  1 NA  5  5  2  2  2 NA  2  1  3  1  3\n [865]  2  4  2  4 NA  4  1  2  3  2  3  3  2  3  2  2  2  1  3  2  4  2 NA  3\n [889]  3  2  2 NA NA  3  2  1  2  4  1  1  1  1  4  3  2 NA  3  2 NA  1 NA  3\n [913]  2  1  1  1  2 NA  2  2  3  3  2 NA NA  4  5  2  2  2  1  2  3  1  3  3\n [937]  4  3 NA  1  1  1 NA  4  3  5  1  1  2 NA  2  2  2  2  5  2  2  3  1  2\n [961]  3 NA  1  2 NA NA  2 NA  3  1  1  2  5  3  5  1  1  4 NA  2  1  3  1  1\n [985]  2  4  3  3  3 NA  1  1  2  2  1  1  2  2 NA  2\n\n\n\n# Count total NA values in the dataset\ntotal_na &lt;- sum(is.na(na_example))\nprint(paste(\"Total NA values in the dataset:\", total_na))\n\n[1] \"Total NA values in the dataset: 145\"\n\n\n\n# Substitute NA values with 660\nna_example_filled &lt;- na_example\nna_example_filled[is.na(na_example_filled)] &lt;- 660\n\n# Display updated dataset without NA values\nprint(\"Updated dataset without NA values:\")\n\n[1] \"Updated dataset without NA values:\"\n\nprint(na_example_filled)\n\n   [1]   2   1   3   2   1   3   1   4   3   2   2 660   2   2   1   4 660   1\n  [19]   1   2   1   2   2   1   2   5 660   2   2   3   1   2   4   1   1   1\n  [37]   4   5   2   3   4   1   2   4   1   1   2   1   5 660 660 660   1   1\n  [55]   5   1   3   1 660   4   4   7   3   2 660 660   1 660   4   1   2   2\n  [73]   3   2   1   2   2   4   3   4   2   3   1   3   2   1   1   1   3   1\n  [91] 660   3   1   2   2   1   2   2   1   1   4   1   1   2   3   3   2   2\n [109]   3   3   3   4   1   1   1   2 660   4   3   4   3   1   2   1 660 660\n [127] 660 660   1   5   1   2   1   3   5   3   2   2 660 660 660 660   3   5\n [145]   3   1   1   4   2   4   3   3 660   2   3   2   6 660   1   1   2   2\n [163]   1   3   1   1   5 660 660   2   4 660   2   5   1   4   3   3 660   4\n [181]   3   1   4   1   1   3   1   1 660 660   3   5   2   2   2   3   1   2\n [199]   2   3   2   1 660   2 660   1 660 660   2   1   1 660   3 660   1   2\n [217]   2   1   3   2   2   1   1   2   3   1   1   1   4   3   4   2   2   1\n [235]   4   1 660   5   1   4 660   3 660 660   1   1   5   2   3   3   2   4\n [253] 660   3   2   5 660   2   3   4   6   2   2   2 660   2 660   2 660   3\n [271]   3   2   2   4   3   1   4   2 660   2   4 660   6   2   3   1 660   2\n [289]   2 660   1   1   3   2   3   3   1 660   1   4   2   1   1   3   2   1\n [307]   2   3   1 660   2   3   3   2   1   2   3   5   5   1   2   3   3   1\n [325] 660 660   1   2   4 660   2   1   1   1   3   2   1   1   3   4 660   1\n [343]   2   1   1   3   3 660   1   1   3   5   3   2   3   4   1   4   3   1\n [361] 660   2   1   2   2   1   2   2   6   1   2   4   5 660   3   4   2   1\n [379]   1   4   2   1   1   1   1   2   1   4   4   1   3 660   3   3 660   2\n [397] 660   1   2   1   1   4   2   1   4   4 660   1   2 660   3   2   2   2\n [415]   1   4   3   6   1   2   3   1   3   2   2   2   1   1   3   2   1   1\n [433]   1   3   2   2 660   4   4   4   1   1 660   4   3 660   1   3   1   3\n [451]   2   4   2   2   2   3   2   1   4   3 660   1   4   3   1   3   2 660\n [469]   3 660   1   3   1   4   1   1   1   2   4   3   1   2   2   2   3   2\n [487]   3   1   1 660   3   2   1   1   2 660   2   2   2   3   3   1   1   2\n [505] 660   1   2   1   1   3   3   1   3   1   1   1   1   1   2   5   1   1\n [523]   2   2   1   1 660   1   4   1   2   4   1   3   2 660   1   1 660   2\n [541]   1   1   4   2   3   3   1   5   3   1   1   2 660   1   1   3   1   3\n [559]   2   4 660   2   3   2   1   2   1   1   1   2   2   3   1   5   2 660\n [577]   2 660   3   2   2   2   1   5   3   2   3   1 660   3   1   2   2   2\n [595]   1   2   2   4 660   6   1   2 660   1   1   2   2   3 660   3   2   3\n [613]   3   4   2 660   2 660   4 660   1   1   2   2   3   1   1   1   3 660\n [631]   2   5 660   7   1 660   4   3   3   1 660   1   1   1   1   3   2   4\n [649]   2   2   3 660 660   1   4   3   2   2   2   3   2   4   2   2   4 660\n [667] 660 660   6   3   3   1   4   4   2   1 660   1   6 660   3   3   2   1\n [685]   1   6 660   1   5   1 660   2   6   2 660   4   1   3   1   2 660   1\n [703]   1   3   1   2   4   2   1   3   2   4   3   2   2   1   1   5   6   4\n [721]   2   2   2   2   4 660   1   2   2   2   2   4   5 660 660 660   4   3\n [739]   3   3   2   4   2   4 660 660 660 660   2   1 660   2   4   3   2 660\n [757]   2   3   1   3   4 660   1   2   1   2 660   3   1   2   1   2   1   2\n [775]   1   2   2   2   2   1   1   3   3   1   3   4   3 660 660   4   2   3\n [793]   2   1   3   2   4   2   2   3   1   2   4   3   3   4 660   1   4   2\n [811]   1   1   1   3   1   5   2   2   4   2 660   1   3   1   2 660   1   2\n [829]   1   2   1 660   1   3   2   3   2 660   2   1   4   2 660 660 660   2\n [847]   4   2 660 660   3   1 660   5   5   2   2   2 660   2   1   3   1   3\n [865]   2   4   2   4 660   4   1   2   3   2   3   3   2   3   2   2   2   1\n [883]   3   2   4   2 660   3   3   2   2 660 660   3   2   1   2   4   1   1\n [901]   1   1   4   3   2 660   3   2 660   1 660   3   2   1   1   1   2 660\n [919]   2   2   3   3   2 660 660   4   5   2   2   2   1   2   3   1   3   3\n [937]   4   3 660   1   1   1 660   4   3   5   1   1   2 660   2   2   2   2\n [955]   5   2   2   3   1   2   3 660   1   2 660 660   2 660   3   1   1   2\n [973]   5   3   5   1   1   4 660   2   1   3   1   1   2   4   3   3   3 660\n [991]   1   1   2   2   1   1   2   2 660   2\n\n\n\n# Count total NA values in the updated dataset (should be 0)\nnew_total_na &lt;- sum(is.na(na_example_filled))\nprint(paste(\"New total NA values in the updated dataset:\", new_total_na))\n\n[1] \"New total NA values in the updated dataset: 0\"\n\n\n\ncount_660 &lt;- sum(na_example_filled == 660)\nprint(paste(\"Total count of instances where the number 660 appears:\", count_660))\n\n[1] \"Total count of instances where the number 660 appears: 145\"",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments/assignment-2.html",
    "href": "assignments/assignment-2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "Assignment 2\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Assignment 2"
    ]
  },
  {
    "objectID": "assignments/assignment-1.html#b",
    "href": "assignments/assignment-1.html#b",
    "title": "Assignment 1",
    "section": "",
    "text": "data(mtcars)\n# Define custom summary function\ncustom_summary &lt;- function(data) {\n  summary_list &lt;- list(\n    mean = mean(data),\n    median = median(data),\n    sd = sd(data),\n    min = min(data),\n    max = max(data)\n  )\n  return(summary_list)\n}\n\nsummary_mpg &lt;- custom_summary(mtcars$mpg)\nprint(summary_mpg)\n\n$mean\n[1] 20.09062\n\n$median\n[1] 19.2\n\n$sd\n[1] 6.026948\n\n$min\n[1] 10.4\n\n$max\n[1] 33.9\n\n\n\n# Iterate over numeric columns of mtcars dataset and apply custom summary function\nfor (col in names(mtcars)) {\n  if (is.numeric(mtcars[[col]])) {\n    cat(\"Summary for column:\", col, \"\\n\")\n    print(custom_summary(mtcars[[col]]))\n    cat(\"\\n\")\n  }\n}\n\nSummary for column: mpg \n$mean\n[1] 20.09062\n\n$median\n[1] 19.2\n\n$sd\n[1] 6.026948\n\n$min\n[1] 10.4\n\n$max\n[1] 33.9\n\n\nSummary for column: cyl \n$mean\n[1] 6.1875\n\n$median\n[1] 6\n\n$sd\n[1] 1.785922\n\n$min\n[1] 4\n\n$max\n[1] 8\n\n\nSummary for column: disp \n$mean\n[1] 230.7219\n\n$median\n[1] 196.3\n\n$sd\n[1] 123.9387\n\n$min\n[1] 71.1\n\n$max\n[1] 472\n\n\nSummary for column: hp \n$mean\n[1] 146.6875\n\n$median\n[1] 123\n\n$sd\n[1] 68.56287\n\n$min\n[1] 52\n\n$max\n[1] 335\n\n\nSummary for column: drat \n$mean\n[1] 3.596563\n\n$median\n[1] 3.695\n\n$sd\n[1] 0.5346787\n\n$min\n[1] 2.76\n\n$max\n[1] 4.93\n\n\nSummary for column: wt \n$mean\n[1] 3.21725\n\n$median\n[1] 3.325\n\n$sd\n[1] 0.9784574\n\n$min\n[1] 1.513\n\n$max\n[1] 5.424\n\n\nSummary for column: qsec \n$mean\n[1] 17.84875\n\n$median\n[1] 17.71\n\n$sd\n[1] 1.786943\n\n$min\n[1] 14.5\n\n$max\n[1] 22.9\n\n\nSummary for column: vs \n$mean\n[1] 0.4375\n\n$median\n[1] 0\n\n$sd\n[1] 0.5040161\n\n$min\n[1] 0\n\n$max\n[1] 1\n\n\nSummary for column: am \n$mean\n[1] 0.40625\n\n$median\n[1] 0\n\n$sd\n[1] 0.4989909\n\n$min\n[1] 0\n\n$max\n[1] 1\n\n\nSummary for column: gear \n$mean\n[1] 3.6875\n\n$median\n[1] 4\n\n$sd\n[1] 0.7378041\n\n$min\n[1] 3\n\n$max\n[1] 5\n\n\nSummary for column: carb \n$mean\n[1] 2.8125\n\n$median\n[1] 2\n\n$sd\n[1] 1.6152\n\n$min\n[1] 1\n\n$max\n[1] 8",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments/assignment-1.html#c",
    "href": "assignments/assignment-1.html#c",
    "title": "Assignment 1",
    "section": "",
    "text": "library(dslabs)\ndata(\"na_example\")\nprint(\"Dataset with NA values:\")\n\n[1] \"Dataset with NA values:\"\n\nprint(na_example)\n\n   [1]  2  1  3  2  1  3  1  4  3  2  2 NA  2  2  1  4 NA  1  1  2  1  2  2  1\n  [25]  2  5 NA  2  2  3  1  2  4  1  1  1  4  5  2  3  4  1  2  4  1  1  2  1\n  [49]  5 NA NA NA  1  1  5  1  3  1 NA  4  4  7  3  2 NA NA  1 NA  4  1  2  2\n  [73]  3  2  1  2  2  4  3  4  2  3  1  3  2  1  1  1  3  1 NA  3  1  2  2  1\n  [97]  2  2  1  1  4  1  1  2  3  3  2  2  3  3  3  4  1  1  1  2 NA  4  3  4\n [121]  3  1  2  1 NA NA NA NA  1  5  1  2  1  3  5  3  2  2 NA NA NA NA  3  5\n [145]  3  1  1  4  2  4  3  3 NA  2  3  2  6 NA  1  1  2  2  1  3  1  1  5 NA\n [169] NA  2  4 NA  2  5  1  4  3  3 NA  4  3  1  4  1  1  3  1  1 NA NA  3  5\n [193]  2  2  2  3  1  2  2  3  2  1 NA  2 NA  1 NA NA  2  1  1 NA  3 NA  1  2\n [217]  2  1  3  2  2  1  1  2  3  1  1  1  4  3  4  2  2  1  4  1 NA  5  1  4\n [241] NA  3 NA NA  1  1  5  2  3  3  2  4 NA  3  2  5 NA  2  3  4  6  2  2  2\n [265] NA  2 NA  2 NA  3  3  2  2  4  3  1  4  2 NA  2  4 NA  6  2  3  1 NA  2\n [289]  2 NA  1  1  3  2  3  3  1 NA  1  4  2  1  1  3  2  1  2  3  1 NA  2  3\n [313]  3  2  1  2  3  5  5  1  2  3  3  1 NA NA  1  2  4 NA  2  1  1  1  3  2\n [337]  1  1  3  4 NA  1  2  1  1  3  3 NA  1  1  3  5  3  2  3  4  1  4  3  1\n [361] NA  2  1  2  2  1  2  2  6  1  2  4  5 NA  3  4  2  1  1  4  2  1  1  1\n [385]  1  2  1  4  4  1  3 NA  3  3 NA  2 NA  1  2  1  1  4  2  1  4  4 NA  1\n [409]  2 NA  3  2  2  2  1  4  3  6  1  2  3  1  3  2  2  2  1  1  3  2  1  1\n [433]  1  3  2  2 NA  4  4  4  1  1 NA  4  3 NA  1  3  1  3  2  4  2  2  2  3\n [457]  2  1  4  3 NA  1  4  3  1  3  2 NA  3 NA  1  3  1  4  1  1  1  2  4  3\n [481]  1  2  2  2  3  2  3  1  1 NA  3  2  1  1  2 NA  2  2  2  3  3  1  1  2\n [505] NA  1  2  1  1  3  3  1  3  1  1  1  1  1  2  5  1  1  2  2  1  1 NA  1\n [529]  4  1  2  4  1  3  2 NA  1  1 NA  2  1  1  4  2  3  3  1  5  3  1  1  2\n [553] NA  1  1  3  1  3  2  4 NA  2  3  2  1  2  1  1  1  2  2  3  1  5  2 NA\n [577]  2 NA  3  2  2  2  1  5  3  2  3  1 NA  3  1  2  2  2  1  2  2  4 NA  6\n [601]  1  2 NA  1  1  2  2  3 NA  3  2  3  3  4  2 NA  2 NA  4 NA  1  1  2  2\n [625]  3  1  1  1  3 NA  2  5 NA  7  1 NA  4  3  3  1 NA  1  1  1  1  3  2  4\n [649]  2  2  3 NA NA  1  4  3  2  2  2  3  2  4  2  2  4 NA NA NA  6  3  3  1\n [673]  4  4  2  1 NA  1  6 NA  3  3  2  1  1  6 NA  1  5  1 NA  2  6  2 NA  4\n [697]  1  3  1  2 NA  1  1  3  1  2  4  2  1  3  2  4  3  2  2  1  1  5  6  4\n [721]  2  2  2  2  4 NA  1  2  2  2  2  4  5 NA NA NA  4  3  3  3  2  4  2  4\n [745] NA NA NA NA  2  1 NA  2  4  3  2 NA  2  3  1  3  4 NA  1  2  1  2 NA  3\n [769]  1  2  1  2  1  2  1  2  2  2  2  1  1  3  3  1  3  4  3 NA NA  4  2  3\n [793]  2  1  3  2  4  2  2  3  1  2  4  3  3  4 NA  1  4  2  1  1  1  3  1  5\n [817]  2  2  4  2 NA  1  3  1  2 NA  1  2  1  2  1 NA  1  3  2  3  2 NA  2  1\n [841]  4  2 NA NA NA  2  4  2 NA NA  3  1 NA  5  5  2  2  2 NA  2  1  3  1  3\n [865]  2  4  2  4 NA  4  1  2  3  2  3  3  2  3  2  2  2  1  3  2  4  2 NA  3\n [889]  3  2  2 NA NA  3  2  1  2  4  1  1  1  1  4  3  2 NA  3  2 NA  1 NA  3\n [913]  2  1  1  1  2 NA  2  2  3  3  2 NA NA  4  5  2  2  2  1  2  3  1  3  3\n [937]  4  3 NA  1  1  1 NA  4  3  5  1  1  2 NA  2  2  2  2  5  2  2  3  1  2\n [961]  3 NA  1  2 NA NA  2 NA  3  1  1  2  5  3  5  1  1  4 NA  2  1  3  1  1\n [985]  2  4  3  3  3 NA  1  1  2  2  1  1  2  2 NA  2\n\n\n\n# Count total NA values in the dataset\ntotal_na &lt;- sum(is.na(na_example))\nprint(paste(\"Total NA values in the dataset:\", total_na))\n\n[1] \"Total NA values in the dataset: 145\"\n\n\n\n# Substitute NA values with 660\nna_example_filled &lt;- na_example\nna_example_filled[is.na(na_example_filled)] &lt;- 660\n\n# Display updated dataset without NA values\nprint(\"Updated dataset without NA values:\")\n\n[1] \"Updated dataset without NA values:\"\n\nprint(na_example_filled)\n\n   [1]   2   1   3   2   1   3   1   4   3   2   2 660   2   2   1   4 660   1\n  [19]   1   2   1   2   2   1   2   5 660   2   2   3   1   2   4   1   1   1\n  [37]   4   5   2   3   4   1   2   4   1   1   2   1   5 660 660 660   1   1\n  [55]   5   1   3   1 660   4   4   7   3   2 660 660   1 660   4   1   2   2\n  [73]   3   2   1   2   2   4   3   4   2   3   1   3   2   1   1   1   3   1\n  [91] 660   3   1   2   2   1   2   2   1   1   4   1   1   2   3   3   2   2\n [109]   3   3   3   4   1   1   1   2 660   4   3   4   3   1   2   1 660 660\n [127] 660 660   1   5   1   2   1   3   5   3   2   2 660 660 660 660   3   5\n [145]   3   1   1   4   2   4   3   3 660   2   3   2   6 660   1   1   2   2\n [163]   1   3   1   1   5 660 660   2   4 660   2   5   1   4   3   3 660   4\n [181]   3   1   4   1   1   3   1   1 660 660   3   5   2   2   2   3   1   2\n [199]   2   3   2   1 660   2 660   1 660 660   2   1   1 660   3 660   1   2\n [217]   2   1   3   2   2   1   1   2   3   1   1   1   4   3   4   2   2   1\n [235]   4   1 660   5   1   4 660   3 660 660   1   1   5   2   3   3   2   4\n [253] 660   3   2   5 660   2   3   4   6   2   2   2 660   2 660   2 660   3\n [271]   3   2   2   4   3   1   4   2 660   2   4 660   6   2   3   1 660   2\n [289]   2 660   1   1   3   2   3   3   1 660   1   4   2   1   1   3   2   1\n [307]   2   3   1 660   2   3   3   2   1   2   3   5   5   1   2   3   3   1\n [325] 660 660   1   2   4 660   2   1   1   1   3   2   1   1   3   4 660   1\n [343]   2   1   1   3   3 660   1   1   3   5   3   2   3   4   1   4   3   1\n [361] 660   2   1   2   2   1   2   2   6   1   2   4   5 660   3   4   2   1\n [379]   1   4   2   1   1   1   1   2   1   4   4   1   3 660   3   3 660   2\n [397] 660   1   2   1   1   4   2   1   4   4 660   1   2 660   3   2   2   2\n [415]   1   4   3   6   1   2   3   1   3   2   2   2   1   1   3   2   1   1\n [433]   1   3   2   2 660   4   4   4   1   1 660   4   3 660   1   3   1   3\n [451]   2   4   2   2   2   3   2   1   4   3 660   1   4   3   1   3   2 660\n [469]   3 660   1   3   1   4   1   1   1   2   4   3   1   2   2   2   3   2\n [487]   3   1   1 660   3   2   1   1   2 660   2   2   2   3   3   1   1   2\n [505] 660   1   2   1   1   3   3   1   3   1   1   1   1   1   2   5   1   1\n [523]   2   2   1   1 660   1   4   1   2   4   1   3   2 660   1   1 660   2\n [541]   1   1   4   2   3   3   1   5   3   1   1   2 660   1   1   3   1   3\n [559]   2   4 660   2   3   2   1   2   1   1   1   2   2   3   1   5   2 660\n [577]   2 660   3   2   2   2   1   5   3   2   3   1 660   3   1   2   2   2\n [595]   1   2   2   4 660   6   1   2 660   1   1   2   2   3 660   3   2   3\n [613]   3   4   2 660   2 660   4 660   1   1   2   2   3   1   1   1   3 660\n [631]   2   5 660   7   1 660   4   3   3   1 660   1   1   1   1   3   2   4\n [649]   2   2   3 660 660   1   4   3   2   2   2   3   2   4   2   2   4 660\n [667] 660 660   6   3   3   1   4   4   2   1 660   1   6 660   3   3   2   1\n [685]   1   6 660   1   5   1 660   2   6   2 660   4   1   3   1   2 660   1\n [703]   1   3   1   2   4   2   1   3   2   4   3   2   2   1   1   5   6   4\n [721]   2   2   2   2   4 660   1   2   2   2   2   4   5 660 660 660   4   3\n [739]   3   3   2   4   2   4 660 660 660 660   2   1 660   2   4   3   2 660\n [757]   2   3   1   3   4 660   1   2   1   2 660   3   1   2   1   2   1   2\n [775]   1   2   2   2   2   1   1   3   3   1   3   4   3 660 660   4   2   3\n [793]   2   1   3   2   4   2   2   3   1   2   4   3   3   4 660   1   4   2\n [811]   1   1   1   3   1   5   2   2   4   2 660   1   3   1   2 660   1   2\n [829]   1   2   1 660   1   3   2   3   2 660   2   1   4   2 660 660 660   2\n [847]   4   2 660 660   3   1 660   5   5   2   2   2 660   2   1   3   1   3\n [865]   2   4   2   4 660   4   1   2   3   2   3   3   2   3   2   2   2   1\n [883]   3   2   4   2 660   3   3   2   2 660 660   3   2   1   2   4   1   1\n [901]   1   1   4   3   2 660   3   2 660   1 660   3   2   1   1   1   2 660\n [919]   2   2   3   3   2 660 660   4   5   2   2   2   1   2   3   1   3   3\n [937]   4   3 660   1   1   1 660   4   3   5   1   1   2 660   2   2   2   2\n [955]   5   2   2   3   1   2   3 660   1   2 660 660   2 660   3   1   1   2\n [973]   5   3   5   1   1   4 660   2   1   3   1   1   2   4   3   3   3 660\n [991]   1   1   2   2   1   1   2   2 660   2\n\n\n\n# Count total NA values in the updated dataset (should be 0)\nnew_total_na &lt;- sum(is.na(na_example_filled))\nprint(paste(\"New total NA values in the updated dataset:\", new_total_na))\n\n[1] \"New total NA values in the updated dataset: 0\"\n\n\n\ncount_660 &lt;- sum(na_example_filled == 660)\nprint(paste(\"Total count of instances where the number 660 appears:\", count_660))\n\n[1] \"Total count of instances where the number 660 appears: 145\"",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments/assignment-1.html#a",
    "href": "assignments/assignment-1.html#a",
    "title": "Assignment 1",
    "section": "",
    "text": "Veri Bilimi ve Endüstri Mühendisliği Üzerine Sohbetler - Cem Vardar & Erdi Dasdemir\nMr. Cem Vardar is an experienced Data Scientist with a focus on prescriptive analytics, optimization. He talks about problem solving, industrial engineering and current trends on data analytics. He also mentions about the data related roles and the problem types that should be handled in that role. He presents a study showing the desired qualities and charecteristics for data science roles. Lastly, as a experienced scientist, he shares some valuable suggestions and reading list and finishes with an interactive Q&A session.",
    "crumbs": [
      "Assignment 1"
    ]
  }
]